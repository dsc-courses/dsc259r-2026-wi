{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb8b201",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You'll start seeing this cell in most lectures.\n",
    "# It exists to hide all of the import statements and other setup\n",
    "# code we need in lecture notebooks.\n",
    "from dsc80_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a63a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext pandas_tutor\n",
    "%set_pandas_tutor_options {\"maxDisplayCols\": 8, \"nohover\": True, \"projectorMode\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143de48",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Lecture 2 – DataFrame Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4afdd4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- `numpy` arrays.\n",
    "- From `babypandas` to `pandas`.\n",
    "    - Deep dive into DataFrames.\n",
    "- Accessing subsets of rows and columns in DataFrames.\n",
    "    - `.loc` and `.iloc`.\n",
    "    - Querying (i.e. filtering).\n",
    "- Adding and modifying columns.\n",
    "- `pandas` and `numpy`.\n",
    "    \n",
    "We can't cover every single detail! The [`pandas` documentation](https://pandas.pydata.org/docs/user_guide/index.html#user-guide) will be your friend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaecf86a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## `numpy` arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dc9df4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### `numpy` overview\n",
    "\n",
    "- `numpy` stands for \"numerical Python\". It is a commonly-used Python module that enables **fast** computation involving arrays and matrices.\n",
    "- `numpy`'s main object is the **array**. In `numpy`, arrays are:\n",
    "    - Homogenous – all values are of the same type.\n",
    "    - (Potentially) multi-dimensional.\n",
    "- Computation in `numpy` is fast because:\n",
    "    - Much of it is implemented in C.\n",
    "    - `numpy` arrays are stored more efficiently in memory than, say, Python lists. \n",
    "- [This site](https://cloudxlab.com/blog/numpy-pandas-introduction/) provides a good overview of `numpy` arrays.\n",
    "\n",
    "We use `numpy` to work with sequences of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a82e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(10)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed29adc4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The shape (10,) means that the array only has a single dimension,\n",
    "# of size 10.\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f257f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "2 ** arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a43343",
   "metadata": {},
   "source": [
    "Arrays come equipped with several handy methods; some examples are below, but you can read about them all [here](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ec76f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(2 ** arr).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dfc0a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(2 ** arr).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabeecaf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(2 ** arr).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bab47",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(2 ** arr).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb19cca8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### ⚠️ The dangers of `for`-loops\n",
    "\n",
    "- `for`-loops are slow when processing large datasets. **You will rarely write `for`-loops (except for Lab 1 and Project 1), and may be penalized on assignments for using them when unnecessary!**\n",
    "- One of the biggest benefits of `numpy` is that it supports **vectorized** operations. \n",
    "    - If `a` and `b` are two arrays of the same length, then `a + b` is a new array of the same length containing the element-wise sum of `a` and `b`.\n",
    "- To illustrate how much faster `numpy` arithmetic is than using a `for`-loop, let's compute the squares of the numbers between 0 and 1,000,000:\n",
    "    - Using a `for`-loop.\n",
    "    - Using vectorized arithmetic, through `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c5235",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "squares = []\n",
    "for i in range(1_000_000):\n",
    "    squares.append(i * i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c026a9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In vanilla Python, this takes about 0.04 seconds per loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae0772",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "squares = np.arange(1_000_000) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b6d506",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In `numpy`, this only takes about 0.001 seconds per loop, more than 40x faster! Note that under the hood, `numpy` is also using a `for`-loop, but it's a `for`-loop implemented in C, which is much faster than Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b602e6e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Multi-dimensional arrays\n",
    "\n",
    "While we didn't see these very often in DSC 10, multi-dimensional lists/arrays may have since come up in DSC 20, 30, or 40A (especially in the context of linear algebra).\n",
    "\n",
    "We'll spend a bit of time talking about 2D (and 3D) arrays here, since in some ways, they behave similarly to DataFrames. \n",
    "\n",
    "Below, we create a 2D array from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fdb9b9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nums = np.array([\n",
    "    [5, 1, 9, 7],\n",
    "    [9, 8, 2, 3],\n",
    "    [2, 5, 0, 4]\n",
    "])\n",
    "\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8e7e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nums has 3 rows and 4 columns.\n",
    "nums.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f49585",
   "metadata": {},
   "source": [
    "We can also create 2D arrays by _reshaping_ other arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5574e1d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here, we're asking to reshape np.arange(1, 7)\n",
    "# so that it has 2 rows and 3 columns.\n",
    "a = np.arange(1, 7).reshape((2, 3))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18337230",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Operations along axes\n",
    "\n",
    "In 2D arrays (and DataFrames), axis 0 refers to the rows (up and down) and axis 1 refers to the columns (left and right).\n",
    "\n",
    "<center><img src='imgs/axis-sum.png' width=600></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e7e95",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c93a42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "If we specify `axis=0`, `a.sum` will \"compress\" along axis 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94995957",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58fb1b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "If we specify `axis=1`, `a.sum` will \"compress\" along axis 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a251862",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718f6fbc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Selecting rows and columns from 2D arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b5b4b2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "You can use `[`square brackets`]` to **slice** rows and columns out of an array, using the same slicing conventions you saw in DSC 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6934d0fa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e554b",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accesses row 0 and all columns.\n",
    "a[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e4fdcf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Same as the above.\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f2e35",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accesses all rows and column 1.\n",
    "a[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a049722",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accesses row 0 and columns 1 and onwards.\n",
    "a[0, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f52a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question 🤔 </h3>\n",
    "        \n",
    "Try and predict the value of <code>grid[-1, 1:].sum()</code> without running the code below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a385d42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = (5, 3)\n",
    "grid = np.ones(s) * 2 * np.arange(1, 16).reshape(s)\n",
    "# grid[-1, 1:].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b36a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Example: Image processing\n",
    "\n",
    "`numpy` arrays are homogenous and potentially multi-dimensional.\n",
    "\n",
    "It turns out that **images** can be represented as 3D `numpy` arrays. The color of each pixel can be described with three numbers under the RGB model – a red value, green value, and blue value. Each of these can vary from 0 to 1.\n",
    "\n",
    "<center><img src='imgs/three_d_array.png' width=250><small>(<a href=\"https://e2eml.school/convert_rgb_to_grayscale\">image source</a>)</small></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef1666f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img_path = Path('imgs') / 'bentley.jpg'\n",
    "img = np.asarray(Image.open(img_path)) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c05170",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c5f82",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80128938",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b0383",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Applying a greyscale filter\n",
    "\n",
    "One way to convert an image to greyscale is to average its red, green, and blue values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5a3a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_2d = img.mean(axis=2)\n",
    "mean_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f3f8ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This is just a single red channel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e9aa3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(mean_2d)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0bed73",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We need to _repeat_ `mean_2d` three times along axis 2, to use the same values for the red, green, and blue channels. `np.repeat` will help us here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b025bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.newaxis is an alias for None.\n",
    "# It helps us introduce an additional axis.\n",
    "np.arange(5)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a6db8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.repeat(np.arange(5)[:, np.newaxis], 3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a0699",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_3d = np.repeat(mean_2d[:, :, np.newaxis], 3, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2cf26",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(mean_3d)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2633b72",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Applying a sepia filter\n",
    "\n",
    "Let's sepia-fy Junior!\n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/apple-sepia.png\" width=50%>\n",
    "    <small>\n",
    "(<a href=\"https://support.apple.com/guide/motion/sepia-filter-motn169f8c87/mac\">Image credits</a>)</small>\n",
    "</center>\n",
    "\n",
    "From [here](https://stackoverflow.com/questions/1061093/how-is-a-sepia-tone-created), we can apply this conversion to each pixel.\n",
    "\n",
    "$$\\begin{align*}\n",
    "R_{\\text{sepia}} &= 0.393R + 0.769G + 0.189B \\\\ G_{\\text{sepia}} &= 0.349R + 0.686G + 0.168B \\\\\n",
    "B_{\\text{sepia}} &= 0.272R + 0.534G + 0.131B\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be87f2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sepia_filter = np.array([\n",
    "    [0.393, 0.769, 0.189],\n",
    "    [0.349, 0.686, 0.168],\n",
    "    [0.272, 0.534, 0.131]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed3e3f5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Multiplies each pixel by the sepia_filter matrix.\n",
    "# Then, clips each RGB value to be between 0 and 1.\n",
    "filtered = (img @ sepia_filter.T).clip(0, 1)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58c595",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(filtered)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e091cbf4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Key takeaway: avoid `for`-loops whenever possible!\n",
    "\n",
    "You can do a lot without `for`-loops, both in `numpy` and in `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549d72e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## `pandas` and `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f532e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<center><img src='imgs/python-stack.png' width=60%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5900bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### `pandas` is built upon `numpy`!\n",
    "\n",
    "- A Series in `pandas` is a `numpy` array with an index.\n",
    "- A DataFrame is like a dictionary of columns, each of which is a `numpy` array.\n",
    "- Many operations in `pandas` are fast because they use `numpy`'s implementations.\n",
    "- If you need to access the array underlying a DataFrame or Series, use the `to_numpy` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6552942",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_path = Path('data') / 'dogs43.csv'\n",
    "dogs = pd.read_csv(dog_path)\n",
    "dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da955778",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dogs['lifetime_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91195593",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dogs['lifetime_cost'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c6a1f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### `pandas` data types\n",
    "\n",
    "- Each Series (column) has a `numpy` data type, which refers to the type of the values stored within. Access it using the `dtypes` attribute.\n",
    "- A column's data type determines which operations can be applied to it.\n",
    "- `pandas` tries to guess the correct data types for a given DataFrame, and is often wrong.\n",
    "    - This can lead to incorrect calculations and poor memory/time performance.\n",
    "- As a result, you will often need to explicitly convert between data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372e856",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd039187",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dogs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2484929",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### `pandas` data types\n",
    "\n",
    "Notice that Python `str` types are `object` types in `numpy` and `pandas`.\n",
    "\n",
    "|Pandas dtype|Python type|NumPy type|SQL type|Usage|\n",
    "|---|---|---|---|---|\n",
    "|int64|int|int_, int8,...,int64, uint8,...,uint64|INT, BIGINT| Integer numbers|\n",
    "|float64|float|float_, float16, float32, float64|FLOAT| Floating point numbers|\n",
    "|bool|bool|bool_|BOOL|True/False values|\n",
    "|datetime64 or Timestamp|datetime.datetime|datetime64|DATETIME|Date and time values|\n",
    "|timedelta64 or Timedelta|datetime.timedelta|timedelta64|NA|Differences between two datetimes|\n",
    "|category|NA|NA|ENUM|Finite list of text values|\n",
    "|object|str|string, unicode|NA|Text|\n",
    "|object|NA|object|NA|Mixed types|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca8db1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[This article](https://www.dataquest.io/blog/pandas-big-data/) details how `pandas` stores different data types under the hood.\n",
    "\n",
    "[This article](https://mortada.net/can-integer-operations-overflow-in-python.html#Can-integers-overflow-in-python?) explains how `numpy`/`pandas` `int64` operations differ from vanilla `int` operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea361cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Type conversion\n",
    "\n",
    "You can change the data type of a Series using the `.astype` Series method.\n",
    "\n",
    "For example, we can change the data type of the `'lifetime_cost'` column in `dogs` to be `uint32`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4309975a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c66798",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gives the types as well as the space taken up by the DataFrame.\n",
    "dogs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1ce8c9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dogs = dogs.assign(lifetime_cost=dogs['lifetime_cost'].astype('uint32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87405f1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now, the DataFrame takes up less space! This may be insignificant in our DataFrame, but makes a difference when working with larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581d5ea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dogs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c9de4e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 💡 Pro-Tip: Setting `dtype`s in `read_csv`\n",
    "\n",
    "Usually, we prefer to set the correct dtypes in `read_csv`, since it can help `pandas` load in files more quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65faf7f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dog_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986d34c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dogs = pd.read_csv(dog_path, dtype={'lifetime_cost': 'uint32'})\n",
    "dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae92f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dogs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffa5177",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Axes\n",
    "\n",
    "- The rows and columns of a DataFrame are both stored as Series.\n",
    "- The **axis** specifies the direction of a **slice** of a DataFrame.\n",
    "\n",
    "<center><img src='imgs/axis.png' width=30%></center>\n",
    "\n",
    "- Axis 0 refers to the index (rows).\n",
    "- Axis 1 refers to the columns.\n",
    "- **These are the same axes definitions that 2D `numpy` arrays have!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e91a09c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### DataFrame methods with `axis`\n",
    "\n",
    "- Many Series methods work on DataFrames.\n",
    "- In such cases, the DataFrame method usually applies the Series method to every row or column.\n",
    "- Many of these methods accept an `axis` argument; the default is usually `axis=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e674deb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89854475",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Max element in each column.\n",
    "dogs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5af45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Max element in each row – throws an error since there are different types in each row.\n",
    "# dogs.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6231eb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The number of unique values in each column.\n",
    "dogs.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d387e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# describe doesn't accept an axis argument; it works on every numeric column in the DataFrame it is called on.\n",
    "dogs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52afb2d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Exercise</h3>\n",
    "Pick a dog breed that you personally like or know the name of. Then:\n",
    "<ul>\n",
    "    <li>Try to find a few other dog breeds that are similar in weight to yours in <code>all_dogs</code>.</li>\n",
    "    <li>Which similar breeds have the lowest and highest <code>'lifetime_cost'</code>? <code>'intelligence_rank'</code>?</li>\n",
    "    <li>Are there any similar breeds that you haven't heard of before?</li>\n",
    "</ul>\n",
    "<br>\n",
    "    For fun, look up these dog breeds on the <a href=\"https://www.akc.org/\">AKC website</a> to see what they look like!\n",
    "</div>\n",
    "\n",
    "<!-- As a bonus, look up these dog breeds on the [AKC website](https://www.akc.org/) to see how they look! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5f3e7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_dogs = pd.read_csv(Path('data') / 'all_dogs.csv')\n",
    "all_dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43fffff",
   "metadata": {},
   "source": [
    "## Data granularity and the `groupby` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9832a1f8",
   "metadata": {},
   "source": [
    "### Example: Palmer Penguins\n",
    "\n",
    "<center><img src=\"imgs/lter_penguins.png\" width=60%>\n",
    "<i><a href=\"https://github.com/allisonhorst/palmerpenguins/blob/main/README.md\">Artwork by @allison_horst</a></i>\n",
    "\n",
    "</center>\n",
    "\n",
    "The dataset we'll work with for the rest of the lecture involves various measurements taken of three species of penguins in Antarctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33970580",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame('https://www.youtube-nocookie.com/embed/CCrNAHXUstU?si=-DntSyUNp5Kwitjm&amp;start=11',\n",
    "       width=560, height=315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea01e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "penguins = sns.load_dataset('penguins').dropna()\n",
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac66f41",
   "metadata": {},
   "source": [
    "Here, each row corresponds to a single penguin, and each column corresponds to a different attribute (or feature) we have for each penguin. Data formatted in this way is called [tidy data](https://r4ds.had.co.nz/tidy-data.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9cdf29",
   "metadata": {},
   "source": [
    "### Granularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b5fa9",
   "metadata": {},
   "source": [
    "- Granularity refers to what each observation in a dataset represents.\n",
    "    - Fine: small details.\n",
    "    - Coarse: bigger picture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a070f",
   "metadata": {},
   "source": [
    "- If you can control how your dataset is created, you should opt for **finer granularity**, i.e. for more detail.\n",
    "    - You can always remove details, but it's difficult to add detail that isn't already there.\n",
    "    - But obtaining fine-grained data can take more time/money."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf598e",
   "metadata": {},
   "source": [
    "- Today, we'll focus on how to **remove** details from fine-grained data, in order to help us understand bigger-picture trends in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482abb63",
   "metadata": {},
   "source": [
    "### Aggregating\n",
    "\n",
    "**Aggregating** is the act of combining many values into a single value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0eee9b",
   "metadata": {},
   "source": [
    "- What is the mean `'body_mass_g'` for all penguins?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce9902",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['body_mass_g'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d4c53",
   "metadata": {},
   "source": [
    "- What is the mean `'body_mass_g'` **for each species**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5058146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8a3286",
   "metadata": {},
   "source": [
    "### Naive approach: looping through unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_map = pd.Series([], dtype=float)\n",
    "\n",
    "for species in penguins['species'].unique():\n",
    "    species_only = penguins.loc[penguins['species'] == species]\n",
    "    species_map.loc[species] = species_only['body_mass_g'].mean()\n",
    "\n",
    "species_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5d0b6",
   "metadata": {},
   "source": [
    "- For each unique `'species'`, we make a pass through the entire dataset.\n",
    "    - The asymptotic runtime of this procedure is $\\Theta(ns)$, where $n$ is the number of rows and $s$ is the number of unique species."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee5bee",
   "metadata": {},
   "source": [
    "- While there are other loop-based solutions that only involve a single pass over the DataFrame, we'd like to avoid Python loops entirely, as they're slow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4720bb7b",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "\n",
    "A better solution is to use the `groupby` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52492c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before:\n",
    "penguins['body_mass_g'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc34548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After:\n",
    "penguins.groupby('species')['body_mass_g'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff09fc00",
   "metadata": {},
   "source": [
    "Somehow, the `groupby` method computes what we're looking for in just one line. How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d24fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pt\n",
    "\n",
    "penguins.groupby('species')['body_mass_g'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c044c",
   "metadata": {},
   "source": [
    "### \"Split-apply-combine\" paradigm\n",
    "\n",
    "The `groupby` method involves three steps: **split**, **apply**, and **combine**. This is the same terminology that the [`pandas` documentation](https://pandas.pydata.org/docs/user_guide/groupby.html) uses.\n",
    "\n",
    "<center><img src=\"imgs/image_0.png\" width=40%></center>\n",
    "\n",
    "- **Split** breaks up and \"groups\" the rows of a DataFrame according to the specified **key**. There is one \"group\" for every unique value of the key.\n",
    "\n",
    "- **Apply** uses a function (e.g. aggregation, transformation, filtration) within the individual groups.\n",
    "\n",
    "- **Combine** stitches the results of these operations into an output DataFrame.\n",
    "\n",
    "- The split-apply-combine pattern can be **parallelized** to work on multiple computers or threads, by sending computations for each group to different processors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee41161",
   "metadata": {},
   "source": [
    "### More examples\n",
    "\n",
    "Before we dive into the internals, let's look at a few more examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca95f58",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question 🤔 </h3>\n",
    "\n",
    "\n",
    "What proportion of penguins of each `'species'` live on `'Dream'` island?\n",
    "</div>\n",
    "    \n",
    "Your output should look like:\n",
    "    \n",
    "    species\n",
    "    Adelie       0.38\n",
    "    Chinstrap    1.00\n",
    "    Gentoo       0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb3cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill this in, then respond on dsc80.com/q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea58cb3",
   "metadata": {},
   "source": [
    "## `DataFrameGroupBy` objects and aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a035c0b3",
   "metadata": {},
   "source": [
    "### `DataFrameGroupBy` objects\n",
    "\n",
    "We've just evaluated a few expressions of the following form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09d5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.groupby('species')['bill_length_mm'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f63ad",
   "metadata": {},
   "source": [
    "There are two method calls in the expression above: `.groupby('species')` and `.mean()`. What happens in the `.groupby()` call?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa3b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.groupby('species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ad741",
   "metadata": {},
   "source": [
    "### Peeking under the hood\n",
    "\n",
    "If `df` is a DataFrame, then `df.groupby(key)` returns a `DataFrameGroupBy` object.\n",
    "\n",
    "This object represents the \"split\" in \"split-apply-combine\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6dac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified DataFrame for demonstration:\n",
    "penguins_small = penguins.iloc[[0, 150, 300, 1, 251, 151, 301], [0, 5, 6]]\n",
    "penguins_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ac631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates one group for each unique value in the species column.\n",
    "penguin_groups = penguins_small.groupby('species')\n",
    "penguin_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bab6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pt\n",
    "penguin_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a34e13",
   "metadata": {},
   "source": [
    "`DataFrameGroupBy` objects have a `groups` attribute, which is a dictionary in which the keys are group names and the values are lists of row labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed2df78",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_groups.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847360e1",
   "metadata": {},
   "source": [
    "`DataFrameGroupBy` objects also have a `get_group(key)` method, which returns a DataFrame with only the values for the given key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5fee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_groups.get_group('Chinstrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as the above!\n",
    "penguins_small.query('species == \"Chinstrap\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd45056",
   "metadata": {},
   "source": [
    "We usually don't use these attributes and methods, but they're useful in understanding how `groupby` works under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc7803",
   "metadata": {},
   "source": [
    "### Aggregation\n",
    "\n",
    "- Once we create a `DataFrameGroupBy` object, we need to **apply** some function to each group, and **combine** the results.\n",
    "\n",
    "- The most common operation we apply to each group is an **aggregation**.\n",
    "    - Remember, aggregation is the act of combining many values into a single value.\n",
    "- To perform an aggregation, use an aggregation method on the `DataFrameGroupBy` object, e.g. `.mean()`, `.max()`, or `.median()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e072339",
   "metadata": {},
   "source": [
    "Let's look at some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b55e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade42fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_small.groupby('species')['body_mass_g'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d800ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whoa, what happened in the sex column?\n",
    "penguins_small.groupby('species').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c743972",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_small.groupby('species').last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb98612",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_small.groupby('species').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9616083",
   "metadata": {},
   "source": [
    "### Column independence\n",
    "\n",
    "Within each group, the aggregation method is applied to **each column independently**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae2fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_small.groupby('species').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e119302",
   "metadata": {},
   "source": [
    "It **is not** telling us that there is a `'Male'` `'Adelie'` penguin with a `'body_mass_g'` of `3800.0`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb45f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This penguin is Female!\n",
    "penguins_small.loc[(penguins['species'] == 'Adelie') & (penguins['body_mass_g'] == 3800.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d986482f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question 🤔 </h3>\n",
    "\n",
    "\n",
    "Find the `species`, `island`, and `body_mass_g` of the heaviest `Male` and `Female` penguins in `penguins` (not `penguins_small`).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93ed085",
   "metadata": {},
   "source": [
    "### Column selection and performance implications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe95f4d",
   "metadata": {},
   "source": [
    "- By default, the aggregator will be applied to **all** columns that it can be applied to.\n",
    "    - `max`, `min`, and `sum` are defined on strings, while `median` and `mean` are not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0e74ca",
   "metadata": {},
   "source": [
    "- If we only care about one column, we can select that column before aggregating **to save time**.\n",
    "    - `DataFrameGroupBy` objects support `[]` notation, just like `DataFrame`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d8f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to the big penguins dataset!\n",
    "penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821ffcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works, but involves wasted effort since the other columns had to be aggregated for no reason.\n",
    "penguins.groupby('species').sum()['bill_length_mm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a5d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a SeriesGroupBy object!\n",
    "penguins.groupby('species')['bill_length_mm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e0899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves time!\n",
    "penguins.groupby('species')['bill_length_mm'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9592101",
   "metadata": {},
   "source": [
    "To demonstrate that the former is slower than the latter, we can use `%%timeit`. For reference, we'll also include our earlier `for`-loop-based solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe3a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "penguins.groupby('species').sum()['bill_length_mm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb4ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "penguins.groupby('species')['bill_length_mm'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "species_map = pd.Series([], dtype=float)\n",
    "\n",
    "for species in penguins['species'].unique():\n",
    "    species_only = penguins.loc[penguins['species'] == species]\n",
    "    species_map.loc[species] = species_only['body_mass_g'].mean()\n",
    "\n",
    "species_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b405a0",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "- It's important to understand _what_ each piece of your code evaluates to – in the first two timed examples, the code is almost identical, but the performance is quite different.\n",
    "\n",
    "    ```py\n",
    "    # Slower\n",
    "    penguins.groupby('species').sum()['bill_length_mm']\n",
    "\n",
    "    # Faster\n",
    "    penguins.groupby('species')['bill_length_mm'].sum()\n",
    "    ```\n",
    "\n",
    "- The `groupby` method is much quicker than `for`-looping over the DataFrame in Python. It can often produce results using just a **single, fast pass** over the data, updating the sum, mean, count, min, or other aggregate for each group along the way.\n",
    "- You should **always** select the columns you want after `groupby`, unless you really know what you're doing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907b0f85",
   "metadata": {},
   "source": [
    "## Beyond default aggregation methods\n",
    "\n",
    "- There are many built-in aggregation methods.\n",
    "- What if you want to apply different aggregation methods to different columns?\n",
    "- What if the aggregation method you want to use doesn't already exist in `pandas`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b00ce48",
   "metadata": {},
   "source": [
    "### The `aggregate` method\n",
    "\n",
    "- The `DataFrameGroupBy` object has a general `aggregate` method, which aggregates using one or more operations.\n",
    "    - Remember, aggregation is the act of combining many values into a single value.\n",
    "- There are many ways of using `aggregate`; refer to [the documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html) for a comprehensive list.\n",
    "- Example arguments:\n",
    "    - A single function.\n",
    "    - A list of functions.\n",
    "    - A dictionary mapping column names to functions.\n",
    "- Per [the documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html), `agg` is an alias for `aggregate`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d4c58",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "How many penguins are there of each `'species'`, and what is the mean `'body_mass_g'` of each `'species'`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232dba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(penguins\n",
    " .groupby('species')\n",
    " ['body_mass_g']\n",
    " .aggregate(['count', 'mean'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0edca",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "What is the maximum `'bill_length_mm'` of each `'species'`, and which `'island'`s is each `'species'` found on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a620465",
   "metadata": {},
   "outputs": [],
   "source": [
    "(penguins\n",
    " .groupby('species')\n",
    " .aggregate({'bill_length_mm': 'max', 'island': 'unique'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad33f25",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "What is the **interquartile range** of the `'body_mass_g'` of each `'species'`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ceac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, the argument to agg is a function,\n",
    "# which takes in a pd.Series and returns a scalar.\n",
    "\n",
    "def iqr(s):\n",
    "    return np.percentile(s, 75) - np.percentile(s, 25)\n",
    "\n",
    "(penguins\n",
    " .groupby('species')\n",
    " ['body_mass_g']\n",
    " .agg(iqr)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446477a-e9f4-48b9-a046-17790c8b667a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
